@article{DENHENGST2024102742,
title = {Guideline-informed reinforcement learning for mechanical ventilation in critical care},
journal = {Artificial Intelligence in Medicine},
volume = {147},
pages = {102742},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2023.102742},
url = {https://www.sciencedirect.com/science/article/pii/S0933365723002567},
author = {Floris {den Hengst} and Martijn Otten and Paul Elbers and Frank {van Harmelen} and Vincent Fran√ßois-Lavet and Mark Hoogendoorn},
keywords = {Reinforcement learning, Clinical guidelines, Mechanical ventilation, Critical care, Q-learning, Imitation learning},
abstract = {Reinforcement Learning (RL) has recently found many applications in the healthcare domain thanks to its natural fit to clinical decision-making and ability to learn optimal decisions from observational data. A key challenge in adopting RL-based solution in clinical practice, however, is the inclusion of existing knowledge in learning a suitable solution. Existing knowledge from e.g. medical guidelines may improve the safety of solutions, produce a better balance between short- and long-term outcomes for patients and increase trust and adoption by clinicians. We present a framework for including knowledge available from medical guidelines in RL. The framework includes components for enforcing safety constraints and an approach that alters the learning signal to better balance short- and long-term outcomes based on these guidelines. We evaluate the framework by extending an existing RL-based mechanical ventilation (MV) approach with clinically established ventilation guidelines. Results from off-policy policy evaluation indicate that our approach has the potential to decrease 90-day mortality while ensuring lung protective ventilation. This framework provides an important stepping stone towards implementations of RL in clinical practice and opens up several avenues for further research.}
}