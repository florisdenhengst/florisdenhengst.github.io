<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Teaching | Floris den Hengst&#39;s Homepage</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
	<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML'
		    async></script>
    
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/publications/">Publications</a></li>
      
      <li><a href="/teaching/">Teaching</a></li>
      
      <li><a href="/posts/">Posts</a></li>
      
      <li><a href="/about/">About</a></li>
      
      <li><a href="/tags/">Tags</a></li>
      
    </ul>
    <hr/>
    </nav>



<h1>Teaching</h1>


<p>I have been involved in the following coursers:</p>
<ul>
<li><strong>Machine Learning (2025)</strong>: Teacher and lab sessions coordinator for <a href="https://studiegids.vu.nl/en/courses/2024-2025/X_400154#/">this</a> Bsc. AI course</li>
<li><strong>Data Mining Techniques (2024)</strong>: Coordinator of <a href="https://studiegids.vu.nl/en/courses/2023-2024/X_400108#/">this</a> Msc. AI course</li>
<li><strong>Machine Learning &amp; Reasoning in Health (2023-current)</strong>: Guest lecturer for <a href="https://studiegids.vu.nl/en/courses/2024-2025/XM_0102#/">this</a> Msc. AI course</li>
</ul>
<p>I have helped organise the <a href="https://rlsummerschool.com/">Reinforcement Learning Summer School</a>, read more in this <a href="/posts/reinforcement-learning-summer-school/">blog post</a>.</p>
<p>Below is an overview of Bsc. and Msc. thesis projects I have supervised.
In case you are interested in my notes on thesis supervision, read more in this <a href="/posts/student_supervision/">blog post</a>.</p>
<h2 id="msc-theses">Msc theses</h2>
<h3 id="2024">2024</h3>
<ul>
<li>Cas Oude Hoekstra, &ldquo;Symbolic Quantile Regression&rdquo;</li>
<li>Jakub Lewkowicz, &ldquo;Multi-Objective Reinforcement Learning for Portfolio Allocation&rdquo;</li>
<li>Lisa Beek, &ldquo;Multi-objective Deep Reinforcement Learning for Workforce Planning&rdquo;</li>
<li>Yassin ben Allal, &ldquo;The application and benefits of applying Reinforcement Learning in Slate Recommender Systems&rdquo;</li>
<li>Marcia van der Poel, &ldquo;Personalized advice for Diabetes Type 2 management using Machine Learning&rdquo;</li>
</ul>
<h3 id="before-2024">before 2024</h3>
<ul>
<li>Haritha Jayaraman, &ldquo;Estimating the value of a policy based on a guideline based metric using OPE&rdquo;</li>
<li>Stefan Petrescu, &ldquo;Rethinking Log Parsing in the Context of Modern Software Ecosystems&rdquo;</li>
<li>Yannick Smit, &ldquo;Strategic Workforce Planning with Deep Reinforcement Learning&rdquo;</li>
<li>Michal Nauman, <a href="https://arxiv.org/abs/2010.15622">&ldquo;Low-Variance Policy Gradient Estimation with World Models&rdquo;</a></li>
<li>Azamat Omuraliev, &ldquo;Reinforcement Learning for Controllable Text Summarization&rdquo;</li>
<li>Mickey van Zeelt, &ldquo;Gathering External Evaluations on Chatbot Conversations&rdquo;</li>
<li>Tim Nederveen, &ldquo;Reducing Expert Interference in Time Series Anomaly Detection Model Re-evaluations&rdquo;</li>
<li>Rob Wanders &ldquo;Predicting Number of Transactions with Echo State Networks&rdquo;</li>
<li>Luca Simonetto &ldquo;Generating Spiking Time Series with Generative Adversarial Networks: an Application on Banking Transactions&rdquo;</li>
<li>Ilse Goedhart &ldquo;Predicting IT Performance using Quantile Regression&rdquo;</li>
</ul>
<h2 id="bsc-theses">Bsc theses</h2>
<h3 id="2024-1">2024</h3>
<ul>
<li>Angel Valencia Orama, Dylan Feteridge &amp; Eduardo Tomasi Kruel, &ldquo;Human-centered Gameplaying with Deep Reinforcement Learning&rdquo;</li>
<li>Luigi Tisci, &ldquo;Reinforcement Learning from Human Feedback for Workforce Optimization&rdquo;</li>
</ul>
<h3 id="before-2024-1">before 2024</h3>
<ul>
<li>Daniel van der Riet, &ldquo;Safe Reinforcement Learning with a Learned Transition Function&rdquo;</li>
<li>Claudia-Violeta Grigorias, &ldquo;Learning safe behaviours with dynamic hyperparameters in Reinforcement Learning&rdquo;</li>
</ul>


<ul>
  
</ul>

  <footer>
  <hr/>
  
  
  <a href="/index.xml"><img src='https://simpleicons.org/icons/rss.svg'></a>
  
  <a href="https://github.com/florisdenhengst/"><img src='https://simpleicons.org/icons/github.svg'></a>
  
  <a href="https://florisdh.bsky.social"><img src='https://simpleicons.org/icons/bluesky.svg'></a>
  
  <a href="https://orcid.org/0000-0002-2092-9904"><img src='/imgs/orcid.svg'></a>
  
  <a href="https://scholar.google.nl/citations?user=8I8iSHkAAAAJ"><img src='/imgs/gscholar.png'></a>
  
  <a href="https://www.linkedin.com/in/floris-den-hengst-06ab7534/"><img src='https://simpleicons.org/icons/linkedin.svg'></a>
  
  | Created with <a href="https://gohugo.io">Hugo</a> and <a href="https://florisdenhengst.github.io/metis-example/">Metis</a> theme | Â© <a href="https://florisdenhengst.github.io">Floris den Hengst</a> 2018 &ndash; 2025
  
  </footer>
  </body>
</html>

